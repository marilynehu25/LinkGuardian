import asyncio
from datetime import datetime

from aiohttp import ClientError, ClientSession

# Importer Celery depuis le fichier d√©di√©
from celery_app import celery
from database import db
from models import TaskRecord, User, Website
from services.api_babbar import fetch_url_data

# üîß CONFIGURATION DES LIMITES D'API
API_RATE_LIMITS = {
    "babbar": {"calls_per_minute": 10, "retry_after": 60},
    "google": {"calls_per_minute": 20, "retry_after": 30},
    "default": {"calls_per_minute": 10, "retry_after": 60},
}


class APIRateLimitError(Exception):
    """Exception lev√©e quand on atteint une limite d'API"""

    def __init__(self, api_name, retry_after=60):
        self.api_name = api_name
        self.retry_after = retry_after
        super().__init__(
            f"Rate limit atteint pour {api_name}. Retry apr√®s {retry_after}s"
        )


async def process_site_async(site_id):

    from services.api_serpapi import check_google_indexation
    from services.check_service import check_link_presence_and_follow_status_async

    site = Website.query.get(site_id)

    async with ClientSession() as session:

        # 1) HTML + ancre
        try:
            link_present, anchor_present, follow_status, status_code = \
                await check_link_presence_and_follow_status_async(
                    session, site.url, site.link_to_check, site.anchor_text
                )
            site.status_code = status_code
            site.link_status = "Lien pr√©sent" if link_present else "URL non pr√©sente"
            site.link_follow_status = follow_status if link_present else None
            site.anchor_status = "Ancre pr√©sente" if anchor_present else "Ancre manquante"
        except Exception as e:
            print("‚ùå HTML ERROR :", repr(e))

        # 2) Google indexing
        try:
            index_status = await check_google_indexation(session, site.url)
            site.google_index_status = index_status
        except Exception as e:
            print("‚ùå GOOGLE ERROR :", repr(e))

        # 3) Babbar
        try:
            babbar_data = fetch_url_data(site.url, async_mode=False)

            if babbar_data:
                site.page_value = babbar_data.get("pageValue")
                site.page_trust = babbar_data.get("pageTrust")
                site.bas = babbar_data.get("babbarAuthorityScore")
                site.backlinks_external = babbar_data.get("backlinksExternal")
                site.num_outlinks_ext = babbar_data.get("numOutLinksExt")

            db.session.commit()
            db.session.refresh(site)

        except Exception as e:
            err = str(e).lower()
            if "limit" in err or "429" in err:
                raise APIRateLimitError("babbar", retry_after=60)
            print("‚ùå BABBAR ERROR :", repr(e))

        # 4) Commit final
        try:
            now = datetime.now()
            site.last_checked = now
            site.first_checked = site.first_checked or now

            db.session.commit()

        except Exception as e:
            print("‚ùå COMMIT ERROR :", repr(e))
            db.session.rollback()
            raise


@celery.task(
    name="tasks.check_single_site",
    bind=True,
    max_retries=5,
    default_retry_delay=60,
    rate_limit="8/m",
    autoretry_for=(APIRateLimitError, ClientError),
    retry_backoff=True,
    retry_backoff_max=600,
    retry_jitter=True,
)
def check_single_site(self, site_id):
    try:
        print(f"üîç V√©rification site ID: {site_id}")

        site = Website.query.get(site_id)
        if not site:
            print(f"‚è≠Ô∏è Site {site_id} supprim√© ‚Äî t√¢che termin√©e")
            return {"success": True, "skipped": True}

        result = asyncio.run(process_site_async(site_id))
        print(f"‚úÖ V√©rification OK pour {site_id}")
        return result

    except APIRateLimitError as exc:
        print(f"‚è≥ Rate limit pour site {site_id}, retry dans {exc.retry_after}s")
        raise self.retry(exc=exc, countdown=exc.retry_after)

    except Exception as exc:
        site = Website.query.get(site_id)
        if site and self.request.retries < self.max_retries:
            print(f"üîÑ Erreur {exc}, retry‚Ä¶")
            raise self.retry(exc=exc)
        print(f"‚ùå Abandon du site {site_id}")
        return {"success": False, "error": str(exc)}


@celery.task(
    name="tasks.check_all_user_sites",
    rate_limit="10/m",  # ‚¨ÜÔ∏è Augment√© de 2/m √† 10/m
)
def check_all_user_sites(user_id):
    """V√©rifie tous les sites d'un utilisateur

    üöÄ OPTIMISATION: Les t√¢ches sont lanc√©es sans countdown.
    Les workers multiples se r√©partissent automatiquement la charge.

    Args:
        user_id: ID de l'utilisateur
        urgent: Si True, les v√©rifications seront prioritaires
    """
    print(f"üìÑ D√©but v√©rification pour l'utilisateur {user_id}")

    sites = Website.query.filter_by(user_id=user_id).all()
    total_sites = len(sites)
    print(f"üìä {total_sites} sites √† v√©rifier")

    if total_sites == 0:
        return {
            "user_id": user_id,
            "total_sites": 0,
            "planned_tasks": 0,
            "skipped_sites": 0,
            "task_ids": [],
        }

    task_ids = []
    skipped = 0

    # üöÄ STRAT√âGIE: Lancer toutes les t√¢ches imm√©diatement
    # Les workers multiples vont se r√©partir le travail automatiquement
    for i, site in enumerate(sites):
        # üßπ V√©rifie que le site est encore valide
        if not site or not site.url:
            skipped += 1
            continue

        # ‚úÖ Lancer la t√¢che SANS countdown
        # Le syst√®me de queues et les multiples workers g√©reront la distribution
        task = check_single_site.apply_async(
            args=[site.id],
            queue="standard",
            priority=5,
        )

        task_ids.append(task.id)

        db.session.add(TaskRecord(task_id=task.id, user_id=user_id))

        # Log tous les 25 sites
        if (i + 1) % 25 == 0:
            print(f"  ‚è≥ {i + 1}/{total_sites} t√¢ches planifi√©es...")

    db.session.commit()

    print(f"‚úÖ {len(task_ids)} t√¢ches lanc√©es ({skipped} sites ignor√©s).")
    print(f"üî• Mode: {'STANDARD'}")

    # Snapshot des stats
    from services.stats_service import save_stats_snapshot

    save_stats_snapshot(user_id)
    

    return {
        "user_id": user_id,
        "total_sites": total_sites,
        "planned_tasks": len(task_ids),
        "skipped_sites": skipped,
        "task_ids": task_ids,
        "mode": "standard",
    }


@celery.task(name="tasks.check_all_sites_weekly")
def check_all_sites_weekly():
    """V√©rification hebdomadaire automatique

    üéØ OPTIMISATION: Espacement entre utilisateurs r√©duit de 30min √† 5min
    Les workers multiples peuvent g√©rer plusieurs utilisateurs simultan√©ment
    """
    print("‚è∞ D√©but v√©rification hebdomadaire")

    users = User.query.all()
    total_users = len(users)

    print(f"üë• {total_users} utilisateurs trouv√©s")

    # üöÄ Espacement r√©duit : 5 minutes entre chaque utilisateur
    # Avec 3+ workers, plusieurs utilisateurs seront trait√©s en parall√®le
    for i, user in enumerate(users):
        countdown = i * 300  # 300s = 5 minutes (au lieu de 30)

        print(
            f"üìÖ V√©rification user {user.id} planifi√©e dans {countdown / 60:.0f} minutes"
        )

        check_all_user_sites.apply_async(
            args=[user.id],
            countdown=countdown,
            queue="weekly",  # Queue d√©di√©e basse priorit√©
        )

    total_duration_hours = (total_users * 5) / 60
    print(f"‚úÖ V√©rifications lanc√©es pour {total_users} utilisateurs")
    print(f"‚è±Ô∏è Dur√©e estim√©e totale: {total_duration_hours:.1f} heures")

    return {
        "total_users": total_users,
        "message": "V√©rification hebdomadaire lanc√©e",
        "estimated_duration_hours": total_duration_hours,
    }


@celery.task(name="tasks.check_task_status")
def check_task_status(task_id):
    """V√©rifie le statut d'une t√¢che"""
    from celery.result import AsyncResult

    result = AsyncResult(task_id, app=celery)

    return {
        "task_id": task_id,
        "state": result.state,
        "result": result.result if result.ready() else None,
        "traceback": result.traceback if result.failed() else None,
    }
